{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hnJLfKi4uBG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install pip==24.0\n",
        "\n",
        "data_path = 'bioactivity_dataset.csv'\n",
        "df= pd.read_csv(data_path)\n",
        "df.drop([\"molecule_chembl_id\"], axis=1, inplace=True)\n",
        "df.head()\n",
        "\n",
        "#Scaling the attributes\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "columns_to_standardize = ['MW', 'LogP', 'NumHDonors', 'NumHAcceptors']\n",
        "scaler = StandardScaler()\n",
        "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
        "\n",
        "#labeling class\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df[\"bioactivity_class\"] = le.fit_transform(df[\"bioactivity_class\"])\n",
        "\n",
        "#minority oversampling\n",
        "\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "df = df.dropna()\n",
        "X = df[['MW', 'LogP', 'NumHDonors', 'NumHAcceptors', 'canonical_smiles']]\n",
        "y = df['bioactivity_class']\n",
        "\n",
        "categorical_features = [4]\n",
        "\n",
        "smote_nc = SMOTENC(categorical_features=categorical_features, random_state=42)\n",
        "X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
        "X_resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "y_resampled_df = pd.DataFrame(y_resampled, columns=['bioactivity_class'])\n",
        "df_resampled = pd.concat([X_resampled_df, y_resampled_df], axis=1)\n",
        "df_resampled.head()\n",
        "\n",
        "#implementation of the biot5 model\n",
        "\n",
        "!pip install simplet5\n",
        "!pip install transformers\n",
        "\n",
        "\n",
        "t5_df = pd.DataFrame(columns=[\"source_text\", \"target_text\"])\n",
        "\n",
        "\n",
        "for i,row in df_resampled.iterrows():\n",
        "  t5_df.loc[len(t5_df)] = {\"source_text\": \"{} {} {} {} {}\".format(str(row[\"canonical_smiles\"]), str(row[\"MW\"]), str(row[\"NumHDonors\"]), str(row[\"LogP\"]), str(row[\"NumHAcceptors\"])),\n",
        "                           \"target_text\": str(row['bioactivity_class'])}\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, remaining_df = train_test_split(t5_df, test_size=0.2, random_state=42)\n",
        "test_df, valid_df = train_test_split(remaining_df, test_size=0.5, random_state=42)\n",
        "print(train_df.shape, test_df.shape, valid_df.shape)\n",
        "\n",
        "\n",
        "from simplet5 import SimpleT5\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Initialize SimpleT5\n",
        "\n",
        "model = SimpleT5()\n",
        "\n",
        "# Load tokenizer and pre-trained model (optional)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"QizhiPei/biot5-base-dti-human\", model_max_length=512)\n",
        "model.from_pretrained(model_type=\"t5\", model_name=\"QizhiPei/biot5-base-dti-human\") # Load pre-trained weights into SimpleT5\n",
        "\n",
        "\n",
        "# Train the model using SimpleT5's train method\n",
        "\n",
        "model.train(train_df=train_df,\n",
        "            eval_df=valid_df,\n",
        "            source_max_token_len=128,\n",
        "            target_max_token_len=50,\n",
        "            batch_size=16, max_epochs=5, use_gpu=True)\n",
        "\n",
        "\n",
        "from simplet5 import SimpleT5\n",
        "\n",
        "# model_path can be found in the outputs folder in colab runtime/local machine\n",
        "# after training is completed. Pick the best 'val-loss-xxx' (lower is better).\n",
        "\n",
        "model_path = \"/content/outputs/simplet5-epoch-2-train-loss-0.0346-val-loss-0.075\"\n",
        "model.load_model(\"t5\",model_path, use_gpu=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "preds = []\n",
        "original = []\n",
        "\n",
        "for i,row in test_df.iterrows():\n",
        "  preds.append(model.predict(row[\"source_text\"]))\n",
        "  original.append(row[\"target_text\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(original, preds))\n"
      ]
    }
  ]
}